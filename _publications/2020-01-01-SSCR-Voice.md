---
title: "Testing the Use of Voice Input in a Smartphone Web Survey"
collection: publications
permalink: /publication/2020-SSCR-Voice
excerpt: '_We implemented an experiment within a smartphone web survey to explore the feasibility of using voice input (VI) options to answer open-ended questions._ [Read more](https://orioljbosch.github.io/publication/2020-SSCR-Voice)'
venue: 'Social Science Computer Review'
paperurl: 'https://journals.sagepub.com/doi/abs/10.1177/0894439318810715'
citation: 'Revilla, M., Couper, M. P., Bosch, O. J., & Asensio, M. (2020). Testing the use of voice input in a smartphone web survey. Social Science Computer Review, 38(2), 207-224.'
---
_Abstract:_ We implemented an experiment within a smartphone web survey to explore the feasibility of using voice input (VI) options. Based on device used, participants were randomly assigned to a treatment or control group. Respondents in the iPhone operating system (iOS) treatment group were asked to use the dictation button, in which the voice was translated automatically into text by the device. Respondents with Android devices were asked to use a VI button which recorded the voice and transmitted the audio file. Both control groups were asked to answer open-ended questions using standard text entry. We found that the use of VI still presents a number of challenges for respondents. Voice recording (Android) led to substantially higher nonresponse, whereas dictation (iOS) led to slightly higher nonresponse, relative to text input. However, completion time was significantly reduced using VI. Among those who provided an answer, when dictation was used, we found fewer valid answers and less information provided, whereas for voice recording, longer and more elaborated answers were obtained. Voice recording (Android) led to significantly lower survey evaluations, but not dictation (iOS).

[Check paper here](https://journals.sagepub.com/doi/abs/10.1177/0894439318810715)
